{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1673259e-4ab1-40d7-add3-44a1bcba6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, SVD, accuracy, KNNBasic, BaselineOnly, NormalPredictor, KNNWithMeans, SVDpp, Trainset\n",
    "from surprise.model_selection import cross_validate, train_test_split, KFold\n",
    "from surprise.accuracy import rmse, mae, mse\n",
    "from surprise.similarities import cosine\n",
    "from surprise.prediction_algorithms.predictions import Prediction\n",
    "from collections import namedtuple, defaultdict\n",
    "from scipy.stats import gaussian_kde, norm\n",
    "from scipy.integrate import quad\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import time\n",
    "import csv\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be19c73-600d-4827-85ef-62b92e8f344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 15)\n",
    "submit = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41815e2d-a57d-4a3e-a6fb-b77731c1ad75",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e8f639af-8343-402b-8f5e-3dc4a52c6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_function(x, k, x_0, L):\n",
    "    \"\"\"\n",
    "    k: factor de crecimiento\n",
    "    x_0: Valor de x donde el resultado sera L/2\n",
    "    L: valor maximo de la funcion\n",
    "    \"\"\"\n",
    "    return L / (1 + np.exp(-k * (x - x_0)))\n",
    "\n",
    "train = pd.read_csv('train.csv', sep='|', parse_dates=['fecha_compra'])\n",
    "train['date_value'] = (train.fecha_compra - train.fecha_compra.min()) / (train.fecha_compra.max() - train.fecha_compra.min()) / 4 + 0.75\n",
    "# df_max = train.groupby('customer_id').agg(_max=('cantidad_venta', 'max'))\n",
    "# train = pd.merge(train, df_max, how='left', left_on='customer_id', right_index=True)\n",
    "# train.cantidad_venta = (train.cantidad_venta) / (train['_max')\n",
    "train['cantidad_venta_normalizado'] = train.cantidad_venta.apply(lambda x: logistic_function(x, k=2, x_0=0.3, L=1))\n",
    "train['rating'] = train.cantidad_venta_normalizado * train.date_value\n",
    "if submit:\n",
    "    test_fecha_min, test_fecha_max = pd.to_datetime('2023-02-06'), pd.to_datetime('2023-02-12')\n",
    "else:\n",
    "    test = train[train.fecha_compra > '2023-01-27']\n",
    "    test_fecha_min, test_fecha_max = test.fecha_compra.min(), test.fecha_compra.max()\n",
    "    train = train[train.fecha_compra <= '2023-01-27']\n",
    "train.sort_values(by=['customer_id', 'product_id', 'fecha_compra'], ascending=[True, True, True], inplace=True)\n",
    "# train['day'] = train.fecha_compra.dt.day\n",
    "# train['month'] = train.fecha_compra.dt.month\n",
    "# train['year'] = train.fecha_compra.dt.year\n",
    "product = pd.read_csv('RentabilidadProduct.csv', sep='|')\n",
    "# train = train[(train.fecha_compra > '2022-01-31') & (train.fecha_compra < '2023-02-01')]\n",
    "submission = pd.read_csv('submit_example.csv', index_col='customer_id')\n",
    "values = train.groupby(['customer_id', 'product_id']).agg(rating = ('rating', 'sum'), ultima_fecha = ('fecha_compra', 'max'))\n",
    "if not submit:\n",
    "    values_test = test.groupby(['customer_id', 'product_id']).agg(rating = ('rating', 'sum'), ultima_fecha = ('fecha_compra', 'max'))\n",
    "matrix = pd.pivot_table(values, index='customer_id', columns='product_id', values='rating')\n",
    "std = train.groupby(['customer_id', 'product_id'])['fecha_compra'].diff()\n",
    "product = pd.merge(product, train.drop_duplicates(subset=['product_id', 'business_id'])[['product_id','business_id']], how='right', on='product_id')\n",
    "product['std'] = product.product_id.apply(lambda iid: std.loc[train[train.product_id == iid].index].std().days)\n",
    "\n",
    "propenso = train.groupby(['customer_id']).product_id.agg(['nunique','count'])\n",
    "propenso['propenso'] = propenso['nunique'] / propenso['count']\n",
    "propenso = propenso.drop(['nunique','count'], axis=1)\n",
    "\n",
    "customers = train.drop_duplicates('customer_id')[['customer_id','type_id']].copy().reset_index(drop=True)\n",
    "customers.set_index('customer_id', inplace=True)\n",
    "customers['propenso'] = 1 - propenso\n",
    "\n",
    "def get_product_similarity(iid_1, iid_2, by):\n",
    "    similarity = product.loc[product.product_id == iid_1, by].iloc[0] == product.loc[product.product_id == iid_2, by].iloc[0]\n",
    "    return int(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e179d-42c4-4b25-9caf-222cf78a4ffd",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e7c12b-8798-47a2-bd04-4caf34c053ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(comprados, recomendados):\n",
    "    if comprados.shape[0] == 0:\n",
    "        return 1.\n",
    "    recall = np.intersect1d(comprados, recomendados, assume_unique=True).shape[0] / comprados.shape[0]\n",
    "    return recall\n",
    "\n",
    "def get_user_comprados(uid, dataset):\n",
    "    \"\"\"\n",
    "    Retornar los productos que un usuario ha comprado en el dataset train o test\n",
    "    \"\"\"\n",
    "    comprados = dataset[dataset.customer_id == uid].product_id.unique()\n",
    "    return comprados\n",
    "\n",
    "def get_user_recall_submission(uid, comprados):\n",
    "    recomendados_submission = np.array(submission.loc[uid].str.split()[0][:30]).astype('int')\n",
    "    recall = get_recall(comprados, recomendados_submission)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bf2fa-ba5f-4df9-acaa-4f39974825e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd19768-a47c-4175-95c1-cd32c4b5600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_method = 0.75\n",
    "def plot_fechas_customer_product(uid, iid):\n",
    "    fechas_compra = train[(train.customer_id == uid) & (train.product_id == iid)].fecha_compra\n",
    "    # Crear una serie temporal con las fechas de compra como índice (esto puede ser útil para análisis posteriores)\n",
    "    serie_temporal = pd.Series(data=[1] * len(fechas_compra), index=fechas_compra)\n",
    "    # Visualizar la serie temporal\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(serie_temporal.index, serie_temporal.values, marker='o')\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Compras')\n",
    "    plt.title('Compras por fecha')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_kde_diferencias_fecha_customer_product(uid, iid):\n",
    "    fechas_compra = train[(train.customer_id == uid) & (train.product_id == iid)].fecha_compra\n",
    "    diferencias = fechas_compra.diff()[1:].dt.days\n",
    "    kde = gaussian_kde(diferencias, bw_method=bw_method)\n",
    "    x = np.linspace(0, diferencias.max()*2, 100)\n",
    "    print(diferencias.values)\n",
    "    sns.lineplot(x=x, y=kde(x))\n",
    "\n",
    "def get_probability_customer_product(uid, iid, min_n, max_n):\n",
    "    \"\"\"\n",
    "    Calcula la probabilidad de que un cliente uid compre cierto producto iid entre los (min_n, max_n) dias siguientes\n",
    "    \"\"\"\n",
    "    #print(f'uid={uid}, iid={iid}')\n",
    "    fechas = train[(train.customer_id == uid) & (train.product_id == iid)].fecha_compra\n",
    "    if fechas.count() == 0:\n",
    "        return 0\n",
    "    if fechas.count() == 1:\n",
    "        return 0.00000000000001\n",
    "    diferencias = fechas.diff()[1:].dt.days\n",
    "    if diferencias.shape[0] <= 1 or diferencias.nunique() == 1 :\n",
    "        distribucion_normal = norm(loc=diferencias.mean(), scale=100/diferencias.shape[0])\n",
    "        probability_less_than_n = distribucion_normal.cdf(max_n + 0.5) - distribucion_normal.cdf(min_n - 0.5)\n",
    "    else:\n",
    "        kde = gaussian_kde(diferencias, bw_method=bw_method)\n",
    "        probability_less_than_n = quad(kde, min_n-0.5, max_n+0.5)[0]\n",
    "        if probability_less_than_n == 0:\n",
    "            return 0.000000000001\n",
    "    return probability_less_than_n * values.loc[(uid, iid), 'rating']\n",
    "\n",
    "def get_probability_customer_product_fechas(uid, iid, fecha_min, fecha_max):\n",
    "    \"\"\"\n",
    "    Calcula la probabilidad de que un cliente uid compre un producto iid en las fechas dadas\n",
    "    Estas fechas tienen que ser despues de su ultima compra\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ultima_fecha = values.loc[(uid, iid), 'ultima_fecha']\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    n_min = (fecha_min - ultima_fecha).days\n",
    "    n_max = (fecha_max- ultima_fecha).days\n",
    "    \n",
    "    return get_probability_customer_product(uid, iid, n_min, n_max)\n",
    "\n",
    "def get_kde_recomendados(uid, fecha_min, fecha_max):\n",
    "    \"\"\"\n",
    "    Retorna los recomendados para un cliente uid en las fechas dadas\n",
    "    \"\"\"\n",
    "    probabilidades = [[iid, get_probability_customer_product_fechas(uid, iid, fecha_min, fecha_max)] for iid in matrix.columns]\n",
    "    recomendados = np.array(list(map(lambda x:x[0], sorted(probabilidades, key=lambda x:x[1], reverse=True)[:30])))\n",
    "    return recomendados\n",
    "\n",
    "def get_kde_recomendados_with_probabilities(uid, fecha_min, fecha_max):\n",
    "    \"\"\"\n",
    "    Retorna los recomendados para un cliente uid en las fechas dadas\n",
    "    \"\"\"\n",
    "    probabilidades = [[iid, get_probability_customer_product_fechas(uid, iid, fecha_min, fecha_max)] for iid in matrix.columns]\n",
    "    recomendados = np.array(sorted(probabilidades, key=lambda x:x[1], reverse=True)[:30])\n",
    "    iid_probability = pd.DataFrame(recomendados, columns=['iid', 'probability'])\n",
    "    iid_probability.iid = iid_probability.iid.astype(int)\n",
    "    return iid_probability\n",
    "\n",
    "def get_union_recomendados(uid, fecha_min, fecha_max, kde_weight, cf_weight):\n",
    "\n",
    "    df_cf = pd.DataFrame(get_user_top_n_2_with_rating(uid), columns=['iid', 'probability'])\n",
    "    cf_min, cf_max = df_cf.probability.min(), df_cf.probability.max()\n",
    "    df_cf.probability = (df_cf.probability - cf_min) / cf_max\n",
    "\n",
    "    df_kde = get_kde_recomendados_with_probabilities(uid, fecha_min, fecha_max)\n",
    "    kde_min, kde_max = df_kde.probability.min(), df_kde.probability.max()\n",
    "    df_kde.probability = (df_kde.probability - kde_min) / kde_max\n",
    "\n",
    "    df_kde.probability = df_kde.probability * kde_weight\n",
    "    df_cf.probability = df_cf.probability * cf_weight\n",
    "\n",
    "    recomendados = pd.concat([df_kde, df_cf], ignore_index=True).groupby('iid').sum().sort_values('probability', ascending=False).index[:30]\n",
    "    return recomendados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cde33a-53f5-48c8-b739-c0ec962a89c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# COLLABORATIVE FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da8f0e58-7f1b-4b1a-876a-dc0357130f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x27085564340>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_reset = values.reset_index().drop('ultima_fecha', axis=1)\n",
    "reader = Reader(line_format='user item rating timestamp', rating_scale=(0, values_reset.rating.max()))\n",
    "data = Dataset.load_from_df(values_reset, reader)\n",
    "train_set = data.build_full_trainset()\n",
    "if not submit:\n",
    "    test_set = values_test.reset_index().drop('ultima_fecha', axis=1).values.tolist()\n",
    "algo = SVD(n_factors=200, n_epochs=40, init_mean=0, init_std_dev=0.1)\n",
    "algo.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57b6889-9bbc-4f14-9536-48b7134be42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.0343  3.2118  3.0118  3.1153  3.0415  3.0830  0.0732  \n",
      "Fit time          3.03    3.26    3.33    3.05    3.16    3.16    0.12    \n",
      "Test time         0.16    0.33    0.15    0.13    0.15    0.18    0.07    \n"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_from_df(values_reset[:100000], reader)\n",
    "y = cross_validate(algo, data, verbose=True, measures=['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a610e41-819f-47f1-844f-eb395ec426e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.3840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3839997128898065"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = algo.test(values.reset_index().drop('ultima_fecha', axis=1).values.tolist())\n",
    "rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23f9fc0d-9cde-4940-87fa-b18d5ccdd46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=30):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def get_user_top_n_2(uid):\n",
    "    \"\"\"\n",
    "    Retornar los 50 productos con mayor probabilidad para un usuario uid\n",
    "    \"\"\"\n",
    "    predictions = list()\n",
    "    for iid in matrix.columns:\n",
    "        if np.isnan(matrix.loc[uid, iid]):\n",
    "            prediction = algo.predict(uid, iid)\n",
    "        else:\n",
    "            prediction = Prediction(uid, iid, matrix.loc[uid,iid], matrix.loc[uid,iid], dict())\n",
    "        predictions.append(prediction)\n",
    "    top_n = get_top_n(predictions, n=30)\n",
    "    top_n_iid = [iid for (iid, rating) in top_n[uid]]\n",
    "    recomendados = np.array(top_n_iid)\n",
    "    return recomendados\n",
    "\n",
    "def get_user_top_n_2_with_rating(uid):\n",
    "    \"\"\"\n",
    "    Retornar los 50 productos con mayor probabilidad para un usuario uid\n",
    "    \"\"\"\n",
    "    predictions = list()\n",
    "    for iid in matrix.columns:\n",
    "        if np.isnan(matrix.loc[uid, iid]):\n",
    "            prediction = algo.predict(uid, iid)\n",
    "        else:\n",
    "            prediction = Prediction(uid, iid, matrix.loc[uid,iid], matrix.loc[uid,iid], dict())\n",
    "        predictions.append(prediction)\n",
    "    top_n = get_top_n(predictions, n=30)\n",
    "    return top_n[uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1585a7-9c3e-490c-9fc8-40ab7f7b2304",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49ad2cb-32d4-4293-972b-c98928e1e75f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13844\\2273514431.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0muid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#for uid in test.groupby('customer_id').product_id.count().sort_values()[-n:].index:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mcomprados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_user_comprados\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mrecomendados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_kde_recomendados\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_fecha_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_fecha_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mrecomendados_CF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_user_top_n_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "recall_kde_sum = 0\n",
    "recall_CF_sum = 0\n",
    "recall_unidos_sum = 0\n",
    "recall_submission_sum = 0\n",
    "#for uid in matrix.index[:n]:\\\n",
    "n = 5\n",
    "#for uid in customers[customers.index.isin(test.customer_id.unique())].sort_values('propenso')[:n].index:\n",
    "for uid in np.random.choice(matrix.index, size=n):\n",
    "#for uid in test.groupby('customer_id').product_id.count().sort_values()[-n:].index:\n",
    "    comprados = get_user_comprados(uid, test)\n",
    "    recomendados = get_kde_recomendados(uid, test_fecha_min, test_fecha_max)\n",
    "    recomendados_CF = get_user_top_n_2(uid)\n",
    "    recomendados_unidos = get_union_recomendados(uid, test_fecha_min, test_fecha_max, kde_weight=10, cf_weight=0.00000000000001)\n",
    "    recall_kde_sum += get_recall(comprados, recomendados)\n",
    "    recall_CF_sum += get_recall(comprados, recomendados_CF)\n",
    "    recall_unidos_sum += get_recall(comprados, recomendados_unidos)\n",
    "    recall_submission_sum += get_user_recall_submission(uid, comprados)\n",
    "print(f'avg kde: {recall_kde_sum/n}, avg CF: {recall_CF_sum/n}, avg unidos: {recall_unidos_sum/n}, avg submission: {recall_submission_sum/n}')\n",
    "end = time.time()\n",
    "print(f'time: {end - start}')\n",
    "print(f'comprados: {comprados}')\n",
    "print(f'recomendados: {recomendados}')\n",
    "print(f'recomendados_CF: {recomendados_CF}')\n",
    "print(f'recomendados_CF y KDE: {np.intersect1d(recomendados, recomendados_CF)}')\n",
    "print(f'comprados y recomendados: {np.intersect1d(comprados, recomendados)}')\n",
    "print(f'comprados y recomendados_CF: {np.intersect1d(comprados, recomendados_CF)}')\n",
    "print(f'comprados y no recomendados: {np.setdiff1d(comprados, recomendados)}')\n",
    "print(f'comprados y no recomendados_CF: {np.setdiff1d(comprados, recomendados_CF)}')\n",
    "print(f'recomendados y comprados por CF y no KDE: {np.setdiff1d(np.intersect1d(recomendados_CF, comprados), recomendados)}')\n",
    "print(f'nuevos comprados: {np.setdiff1d(comprados, get_user_comprados(uid, train))}')\n",
    "print(f'cantidad de productos unicos comprados: {get_user_comprados(uid, train).shape[0]}')\n",
    "print(f'propenso: {customers.loc[uid, \"propenso\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "182e8bdb-d5f6-4db3-a15c-628fc42ef906",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.drop(index=[1,2,3,4,5], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f6b4b6ee-90e3-40d5-8eb5-0edd56bec74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in customers.index.astype('str').sort_values().astype('int64')[:5]:\n",
    "    recomendados = get_kde_recomendados(uid, test_fecha_min, test_fecha_max)\n",
    "    submission.at[uid, 'product_id'] = ' '.join(map(str, recomendados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "25fcd848-c839-4c3b-a4be-fdafb3401d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submit.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
